{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/gautam/.local/lib/python3.8/site-packages (1.24.4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Requirement already satisfied: pandas in /home/gautam/.local/lib/python3.8/site-packages (2.0.3)',\n",
       " 'Requirement already satisfied: pytz>=2020.1 in /home/gautam/.local/lib/python3.8/site-packages (from pandas) (2024.1)',\n",
       " 'Requirement already satisfied: python-dateutil>=2.8.2 in /home/gautam/.local/lib/python3.8/site-packages (from pandas) (2.9.0.post0)',\n",
       " 'Requirement already satisfied: tzdata>=2022.1 in /home/gautam/.local/lib/python3.8/site-packages (from pandas) (2024.1)',\n",
       " 'Requirement already satisfied: numpy>=1.20.3; python_version < \"3.10\" in /home/gautam/.local/lib/python3.8/site-packages (from pandas) (1.24.4)',\n",
       " 'Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.14.0)']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Job Title', 'Job Description', 'Job Type', 'Categories', 'Location',\n",
      "       'City', 'State', 'Country', 'Zip Code', 'Address', 'Salary From',\n",
      "       'Salary To', 'Salary Period', 'Apply Url', 'Apply Email', 'Employees',\n",
      "       'Industry', 'Company Name', 'Employer Email', 'Employer Website',\n",
      "       'Employer Phone', 'Employer Logo', 'Companydescription',\n",
      "       'Employer Location', 'Employer City', 'Employer State',\n",
      "       'Employer Country', 'Employer Zip Code', 'Uniq Id', 'Crawl Timestamp'],\n",
      "      dtype='object')\n",
      "                       Job Title  \\\n",
      "0                  Shift Manager   \n",
      "1     Operations Support Manager   \n",
      "2  Senior Product Manager - Data   \n",
      "3     Part-Time Office Concierge   \n",
      "4    Print & Marketing Associate   \n",
      "\n",
      "                                     Job Description  Job Type  Categories  \\\n",
      "0  <div id=\"jobDescriptionText\" class=\"jobsearch-...       NaN         NaN   \n",
      "1  <div id=\"jobDescriptionText\" class=\"jobsearch-...       NaN         NaN   \n",
      "2  <div id=\"jobDescriptionText\" class=\"jobsearch-...       NaN         NaN   \n",
      "3  <div id=\"jobDescriptionText\" class=\"jobsearch-...       NaN         NaN   \n",
      "4  <div id=\"jobDescriptionText\" class=\"jobsearch-...       NaN         NaN   \n",
      "\n",
      "                  Location           City State        Country Zip Code  \\\n",
      "0  Mission Hills, CA 91345  Mission Hills    CA  United States    91345   \n",
      "1        Atlanta, GA 30342        Atlanta    GA  United States    30342   \n",
      "2              Chicago, IL        Chicago    IL  United States      NaN   \n",
      "3               Festus, MO         Festus    MO  United States      NaN   \n",
      "4   Cedar Rapids, IA 52404   Cedar Rapids    IA  United States    52404   \n",
      "\n",
      "   Address  ...  Employer Phone  \\\n",
      "0      NaN  ...             NaN   \n",
      "1      NaN  ...             NaN   \n",
      "2      NaN  ...             NaN   \n",
      "3      NaN  ...             NaN   \n",
      "4      NaN  ...             NaN   \n",
      "\n",
      "                                       Employer Logo  \\\n",
      "0  https://d2q79iu7y748jz.cloudfront.net/s/_squar...   \n",
      "1  https://d2q79iu7y748jz.cloudfront.net/s/_logo/...   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4  https://d2q79iu7y748jz.cloudfront.net/s/_logo/...   \n",
      "\n",
      "                                  Companydescription        Employer Location  \\\n",
      "0  Del Taco is an American quick service restaura...  Mission Hills, CA 91345   \n",
      "1  Based in Atlanta, FOCUS Brands Inc. is an inno...                      NaN   \n",
      "2  Vibes Corp. reputation was built and establish...                      NaN   \n",
      "3                                                NaN                      NaN   \n",
      "4  Staples is The Worklife Fulfillment Company, h...   Cedar Rapids, IA 52404   \n",
      "\n",
      "   Employer City  Employer State  Employer Country Employer Zip Code  \\\n",
      "0  Mission Hills              CA     United States             91345   \n",
      "1            NaN             NaN     United States               NaN   \n",
      "2            NaN             NaN     United States               NaN   \n",
      "3            NaN             NaN     United States               NaN   \n",
      "4   Cedar Rapids              IA     United States             52404   \n",
      "\n",
      "                            Uniq Id            Crawl Timestamp  \n",
      "0  511f9a53920f4641d701d51d3589349f  2019-08-24 09:13:18 +0000  \n",
      "1  4955daf0a3facbe2acb6c429ba394e6d  2019-09-19 08:16:55 +0000  \n",
      "2  a0e0d12df1571962b785f17f43ceae12  2019-09-18 02:13:10 +0000  \n",
      "3  56e411fd731f76ac916bf4fb169250e9  2019-10-24 16:39:13 +0000  \n",
      "4  3fff5c0ad6981bf4bff6260bd5feab63  2019-08-24 22:29:10 +0000  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "job_posting_data = pd.read_csv(\"./marketing_sample_for_trulia_com-real_estate__20190901_20191031__30k_data.csv\")\n",
    "\n",
    "print(job_posting_data.keys())\n",
    "print(job_posting_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Location</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Address</th>\n",
       "      <th>...</th>\n",
       "      <th>Employer Phone</th>\n",
       "      <th>Employer Logo</th>\n",
       "      <th>Companydescription</th>\n",
       "      <th>Employer Location</th>\n",
       "      <th>Employer City</th>\n",
       "      <th>Employer State</th>\n",
       "      <th>Employer Country</th>\n",
       "      <th>Employer Zip Code</th>\n",
       "      <th>Uniq Id</th>\n",
       "      <th>Crawl Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shift Manager</td>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mission Hills, CA 91345</td>\n",
       "      <td>Mission Hills</td>\n",
       "      <td>CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>91345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://d2q79iu7y748jz.cloudfront.net/s/_squar...</td>\n",
       "      <td>Del Taco is an American quick service restaura...</td>\n",
       "      <td>Mission Hills, CA 91345</td>\n",
       "      <td>Mission Hills</td>\n",
       "      <td>CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>91345</td>\n",
       "      <td>511f9a53920f4641d701d51d3589349f</td>\n",
       "      <td>2019-08-24 09:13:18 +0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Operations Support Manager</td>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlanta, GA 30342</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>United States</td>\n",
       "      <td>30342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://d2q79iu7y748jz.cloudfront.net/s/_logo/...</td>\n",
       "      <td>Based in Atlanta, FOCUS Brands Inc. is an inno...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4955daf0a3facbe2acb6c429ba394e6d</td>\n",
       "      <td>2019-09-19 08:16:55 +0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Product Manager - Data</td>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vibes Corp. reputation was built and establish...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a0e0d12df1571962b785f17f43ceae12</td>\n",
       "      <td>2019-09-18 02:13:10 +0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Part-Time Office Concierge</td>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Festus, MO</td>\n",
       "      <td>Festus</td>\n",
       "      <td>MO</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56e411fd731f76ac916bf4fb169250e9</td>\n",
       "      <td>2019-10-24 16:39:13 +0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Print &amp; Marketing Associate</td>\n",
       "      <td>&lt;div id=\"jobDescriptionText\" class=\"jobsearch-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cedar Rapids, IA 52404</td>\n",
       "      <td>Cedar Rapids</td>\n",
       "      <td>IA</td>\n",
       "      <td>United States</td>\n",
       "      <td>52404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://d2q79iu7y748jz.cloudfront.net/s/_logo/...</td>\n",
       "      <td>Staples is The Worklife Fulfillment Company, h...</td>\n",
       "      <td>Cedar Rapids, IA 52404</td>\n",
       "      <td>Cedar Rapids</td>\n",
       "      <td>IA</td>\n",
       "      <td>United States</td>\n",
       "      <td>52404</td>\n",
       "      <td>3fff5c0ad6981bf4bff6260bd5feab63</td>\n",
       "      <td>2019-08-24 22:29:10 +0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Job Title  \\\n",
       "0                  Shift Manager   \n",
       "1     Operations Support Manager   \n",
       "2  Senior Product Manager - Data   \n",
       "3     Part-Time Office Concierge   \n",
       "4    Print & Marketing Associate   \n",
       "\n",
       "                                     Job Description  Job Type  Categories  \\\n",
       "0  <div id=\"jobDescriptionText\" class=\"jobsearch-...       NaN         NaN   \n",
       "1  <div id=\"jobDescriptionText\" class=\"jobsearch-...       NaN         NaN   \n",
       "2  <div id=\"jobDescriptionText\" class=\"jobsearch-...       NaN         NaN   \n",
       "3  <div id=\"jobDescriptionText\" class=\"jobsearch-...       NaN         NaN   \n",
       "4  <div id=\"jobDescriptionText\" class=\"jobsearch-...       NaN         NaN   \n",
       "\n",
       "                  Location           City State        Country Zip Code  \\\n",
       "0  Mission Hills, CA 91345  Mission Hills    CA  United States    91345   \n",
       "1        Atlanta, GA 30342        Atlanta    GA  United States    30342   \n",
       "2              Chicago, IL        Chicago    IL  United States      NaN   \n",
       "3               Festus, MO         Festus    MO  United States      NaN   \n",
       "4   Cedar Rapids, IA 52404   Cedar Rapids    IA  United States    52404   \n",
       "\n",
       "   Address  ...  Employer Phone  \\\n",
       "0      NaN  ...             NaN   \n",
       "1      NaN  ...             NaN   \n",
       "2      NaN  ...             NaN   \n",
       "3      NaN  ...             NaN   \n",
       "4      NaN  ...             NaN   \n",
       "\n",
       "                                       Employer Logo  \\\n",
       "0  https://d2q79iu7y748jz.cloudfront.net/s/_squar...   \n",
       "1  https://d2q79iu7y748jz.cloudfront.net/s/_logo/...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  https://d2q79iu7y748jz.cloudfront.net/s/_logo/...   \n",
       "\n",
       "                                  Companydescription        Employer Location  \\\n",
       "0  Del Taco is an American quick service restaura...  Mission Hills, CA 91345   \n",
       "1  Based in Atlanta, FOCUS Brands Inc. is an inno...                      NaN   \n",
       "2  Vibes Corp. reputation was built and establish...                      NaN   \n",
       "3                                                NaN                      NaN   \n",
       "4  Staples is The Worklife Fulfillment Company, h...   Cedar Rapids, IA 52404   \n",
       "\n",
       "   Employer City  Employer State  Employer Country Employer Zip Code  \\\n",
       "0  Mission Hills              CA     United States             91345   \n",
       "1            NaN             NaN     United States               NaN   \n",
       "2            NaN             NaN     United States               NaN   \n",
       "3            NaN             NaN     United States               NaN   \n",
       "4   Cedar Rapids              IA     United States             52404   \n",
       "\n",
       "                            Uniq Id            Crawl Timestamp  \n",
       "0  511f9a53920f4641d701d51d3589349f  2019-08-24 09:13:18 +0000  \n",
       "1  4955daf0a3facbe2acb6c429ba394e6d  2019-09-19 08:16:55 +0000  \n",
       "2  a0e0d12df1571962b785f17f43ceae12  2019-09-18 02:13:10 +0000  \n",
       "3  56e411fd731f76ac916bf4fb169250e9  2019-10-24 16:39:13 +0000  \n",
       "4  3fff5c0ad6981bf4bff6260bd5feab63  2019-08-24 22:29:10 +0000  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_posting_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-2.5.1-py3-none-any.whl (156 kB)\n",
      "Requirement already satisfied: numpy in /home/gautam/.local/lib/python3.8/site-packages (from sentence-transformers) (1.24.4)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Collecting transformers<5.0.0,>=4.32.0\n",
      "  Using cached transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
      "Collecting torch>=1.11.0\n",
      "  Using cached torch-2.2.1-cp38-cp38-manylinux1_x86_64.whl (755.5 MB)\n",
      "Requirement already satisfied: Pillow in /usr/lib/python3/dist-packages (from sentence-transformers) (7.0.0)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
      "Collecting huggingface-hub>=0.15.1\n",
      "  Using cached huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Using cached safetensors-0.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2023.12.25-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (777 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Collecting tokenizers<0.19,>=0.14\n",
      "  Using cached tokenizers-0.15.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2.22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (5.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/gautam/.local/lib/python3.8/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (24.0)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting jinja2\n",
      "  Using cached Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[K     |████████████████████████████████| 171 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting triton==2.2.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.12\"\n",
      "  Using cached triton-2.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/gautam/.local/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (4.10.0)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.3.0-py3-none-any.whl (17 kB)\n",
      "Collecting joblib>=1.1.1\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26 kB)\n",
      "Collecting nvidia-nvjitlink-cu12\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Collecting mpmath>=0.19\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: tqdm, safetensors, fsspec, filelock, huggingface-hub, regex, tokenizers, transformers, nvidia-cublas-cu12, nvidia-cuda-nvrtc-cu12, nvidia-nvtx-cu12, networkx, nvidia-cuda-runtime-cu12, MarkupSafe, jinja2, nvidia-cuda-cupti-cu12, nvidia-cudnn-cu12, nvidia-nvjitlink-cu12, nvidia-cusparse-cu12, nvidia-cusolver-cu12, nvidia-nccl-cu12, nvidia-cufft-cu12, triton, mpmath, sympy, nvidia-curand-cu12, torch, scipy, threadpoolctl, joblib, scikit-learn, sentence-transformers\n",
      "Successfully installed MarkupSafe-2.1.5 filelock-3.13.1 fsspec-2024.3.1 huggingface-hub-0.21.4 jinja2-3.1.3 joblib-1.3.2 mpmath-1.3.0 networkx-3.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 regex-2023.12.25 safetensors-0.4.2 scikit-learn-1.3.2 scipy-1.10.1 sentence-transformers-2.5.1 sympy-1.12 threadpoolctl-3.3.0 tokenizers-0.15.2 torch-2.2.1 tqdm-4.66.2 transformers-4.38.2 triton-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/home/gautam/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embedding: (384,)\n",
      "Embedding array slice:  [ 0.02834189 -0.4729128  -0.20220165 -0.22404514  0.09101413  0.10281014\n",
      " -0.24427006  0.19842336 -0.53361094 -0.06845693 -0.7373882   0.27506983\n",
      " -0.49564335  0.01144942 -0.2514727   0.3541341   0.00965727 -0.23656641\n",
      "  0.48507577 -0.441235    0.7613262  -0.27653253  0.13975342 -0.49943903\n",
      "  0.7144036   0.09835684  0.26417723 -0.17323968 -0.32750607 -0.3680155 ]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class EmbeddingGenerator:\n",
    "    def __init__(self, model_name='paraphrase-MiniLM-L6-v2'):\n",
    "        \"\"\"\n",
    "        Initialize the Embedding Generator with a specified model.\n",
    "        \n",
    "        :param model_name: Name of the sentence-transformers model to use.\n",
    "        \"\"\"\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def generate_embedding(self, sentence):\n",
    "        \"\"\"\n",
    "        Generate an embedding for the given sentence.\n",
    "\n",
    "        :param sentence: Input text sentence.\n",
    "        :return: Embedding as a numpy array.\n",
    "        \"\"\"\n",
    "        return self.model.encode(sentence)\n",
    "\n",
    "# Example usage:\n",
    "generator = EmbeddingGenerator()\n",
    "embedding = generator.generate_embedding(\"Software engineer in New York\")\n",
    "print(\"Shape of embedding:\" , embedding.shape)\n",
    "print(\"Embedding array slice: \", embedding[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /home/gautam/.local/lib/python3.8/site-packages (3.7.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/gautam/.local/lib/python3.8/site-packages (from spacy) (2.6.4)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/gautam/.local/lib/python3.8/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/gautam/.local/lib/python3.8/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/gautam/.local/lib/python3.8/site-packages (from spacy) (4.66.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/gautam/.local/lib/python3.8/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/gautam/.local/lib/python3.8/site-packages (from spacy) (24.0)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/gautam/.local/lib/python3.8/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/gautam/.local/lib/python3.8/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/gautam/.local/lib/python3.8/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/gautam/.local/lib/python3.8/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: jinja2 in /home/gautam/.local/lib/python3.8/site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/gautam/.local/lib/python3.8/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/gautam/.local/lib/python3.8/site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy) (45.2.0)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /home/gautam/.local/lib/python3.8/site-packages (from spacy) (8.2.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/gautam/.local/lib/python3.8/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/gautam/.local/lib/python3.8/site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: numpy>=1.15.0; python_version < \"3.9\" in /home/gautam/.local/lib/python3.8/site-packages (from spacy) (1.24.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/gautam/.local/lib/python3.8/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/gautam/.local/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/gautam/.local/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/gautam/.local/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.10.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/gautam/.local/lib/python3.8/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/gautam/.local/lib/python3.8/site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/gautam/.local/lib/python3.8/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: confection<0.2.0,>=0.0.4 in /home/gautam/.local/lib/python3.8/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.1.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/gautam/.local/lib/python3.8/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n"
     ]
    }
   ],
   "source": [
    "#Installation\n",
    "!pip install spacy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "Requirement already satisfied: en-core-web-sm==3.7.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl in /home/gautam/.local/lib/python3.8/site-packages (3.7.1)\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in /home/gautam/.local/lib/python3.8/site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/gautam/.local/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/gautam/.local/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/gautam/.local/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/gautam/.local/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0; python_version < \"3.9\" in /home/gautam/.local/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.4)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (45.2.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/gautam/.local/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: jinja2 in /home/gautam/.local/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/gautam/.local/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.4)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /home/gautam/.local/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/gautam/.local/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/gautam/.local/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/gautam/.local/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/gautam/.local/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/gautam/.local/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/gautam/.local/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/gautam/.local/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/gautam/.local/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.22.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/gautam/.local/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: confection<0.2.0,>=0.0.4 in /home/gautam/.local/lib/python3.8/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/gautam/.local/lib/python3.8/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/gautam/.local/lib/python3.8/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/gautam/.local/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.10.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/gautam/.local/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/gautam/.local/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/gautam/.local/lib/python3.8/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/gautam/.local/lib/python3.8/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['New York']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "class NamedEntityRecognizer:\n",
    "    def __init__(self, model_name=\"en_core_web_sm\"):\n",
    "        \"\"\"\n",
    "        Initialize the Named Entity Recognizer with a specified spaCy model.\n",
    "\n",
    "        :param model_name: Name of the spaCy model to use.\n",
    "        \"\"\"\n",
    "        self.nlp = spacy.load(model_name)\n",
    "\n",
    "    def extract_entities(self, sentence, entity_type=None):\n",
    "        \"\"\"\n",
    "        Extract named entities from the given sentence.\n",
    "\n",
    "        :param sentence: Input text sentence.\n",
    "        :param entity_type: Type of the entity (e.g., \"GPE\", \"PERSON\"). \n",
    "                            If None, returns all entity types.\n",
    "        :return: List of extracted entities.\n",
    "        \"\"\"\n",
    "        doc = self.nlp(sentence)\n",
    "        if entity_type:\n",
    "            return [ent.text for ent in doc.ents if ent.label_ == entity_type]\n",
    "        return [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "# Example usage:\n",
    "ner = NamedEntityRecognizer()\n",
    "\n",
    "locations = ner.extract_entities(\"Software engineer in New York\", entity_type=\"GPE\")\n",
    "print(locations)  # ['Paris', 'New York']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Gautam', 'PERSON')]\n"
     ]
    }
   ],
   "source": [
    "entities = ner.extract_entities(\"Gautam checking code.\")\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: elasticsearch in /home/gautam/.local/lib/python3.8/site-packages (8.12.1)\n",
      "Requirement already satisfied: elastic-transport<9,>=8 in /home/gautam/.local/lib/python3.8/site-packages (from elasticsearch) (8.12.0)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from elastic-transport<9,>=8->elasticsearch) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in /home/gautam/.local/lib/python3.8/site-packages (from elastic-transport<9,>=8->elasticsearch) (2.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/gautam/.local/lib/python3.8/site-packages (4.66.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install elasticsearch\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = {\n",
    "        \"embedding\": embedding, #\n",
    "        \"city\": job_posting_data['City'],\n",
    "        \"Job title\": job_posting_data['Job Title']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializaing es\n",
      "initialized es\n",
      "setting up index-------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4886/2871801688.py:20: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  if self.es.indices.exists(index=self.index_name):\n",
      "/tmp/ipykernel_4886/2871801688.py:22: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  self.es.indices.delete(index=self.index_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up index@@@@@@@@@@@@@\n",
      "setting up index\n",
      "setting up index--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4886/2871801688.py:39: ElasticsearchWarning: Parameter [similarity] has no effect on type [dense_vector] and will be removed in future\n",
      "  self.es.indices.create(index=self.index_name, body={\"mappings\": mappings})\n",
      "/tmp/ipykernel_4886/2871801688.py:39: ElasticsearchWarning: Parameter [index] has no effect on type [dense_vector] and will be removed in future\n",
      "  self.es.indices.create(index=self.index_name, body={\"mappings\": mappings})\n",
      "/tmp/ipykernel_4886/2871801688.py:39: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  self.es.indices.create(index=self.index_name, body={\"mappings\": mappings})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started generating embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings: 100%|██████████| 30002/30002 [06:47<00:00, 73.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started ingesting data into Elastic search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing:   0%|          | 0/30002 [00:00<?, ?it/s]/tmp/ipykernel_4886/2871801688.py:63: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  self.es.index(index=self.index_name, body=document)\n",
      "Indexing: 100%|██████████| 30002/30002 [18:06<00:00, 27.61it/s]\n"
     ]
    }
   ],
   "source": [
    "class JobPostingDB:\n",
    "    def __init__(self, index_name=\"job_postings\", host=\"http://localhost:9200/\"):\n",
    "        \"\"\"\n",
    "        Initialize the JobPostingDB with a specified index name.\n",
    "\n",
    "        :param index_name: Name of the Elasticsearch index to use.\n",
    "        \"\"\"\n",
    "        print(\"initializaing es\")\n",
    "        # self.es = Elasticsearch([host], basic_auth=(user, password))\n",
    "        self.es = Elasticsearch([{'host': 'localhost', 'port': 9200, 'scheme': 'http'}])\n",
    "        self.index_name = index_name\n",
    "        self.generator = EmbeddingGenerator()\n",
    "        print(\"initialized es\")\n",
    "\n",
    "    def setup_index(self):\n",
    "        \"\"\"Set up the Elasticsearch index with necessary mappings.\"\"\"\n",
    "        print(\"setting up index-------------------\")\n",
    "\n",
    "        # Check if index exists, and if so, delete\n",
    "        if self.es.indices.exists(index=self.index_name):\n",
    "            print(\"setting up index@@@@@@@@@@@@@\")\n",
    "            self.es.indices.delete(index=self.index_name)\n",
    "        print(\"setting up index\")\n",
    "        \n",
    "        # Define mappings for dense_vector\n",
    "        mappings = {\n",
    "            \"properties\": {\n",
    "                \"embedding\": {\n",
    "                    \"type\": \"dense_vector\",\n",
    "                    \"dims\": 384,  # Assuming embeddings are of size 384, adjust if different\n",
    "                    \"index\": True,\n",
    "                    \"similarity\": \"cosine\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        print(\"setting up index--------------\")\n",
    "\n",
    "        # Create a new index with the defined mappings\n",
    "        self.es.indices.create(index=self.index_name, body={\"mappings\": mappings})\n",
    "\n",
    "    def index_dataframe(self, df):\n",
    "        \"\"\"\n",
    "        Index the DataFrame into Elasticsearch.\n",
    "\n",
    "        :param df: The input DataFrame containing job postings.\n",
    "        \"\"\"\n",
    "        df[\"combined_text\"] = df[\"Job Title\"] #+ df[\"Job Description\"]  # Did not work due to html flags corrupting embedding\n",
    "        print(\"Started generating embeddings\")\n",
    "        \n",
    "        # Use tqdm.pandas() for progress_apply\n",
    "        tqdm.pandas(desc=\"Generating Embeddings\")\n",
    "        embeddings = df[\"combined_text\"].progress_apply(self.generator.generate_embedding)\n",
    "    \n",
    "        print(\"Started ingesting data into Elastic search\")\n",
    "        # Wrap the dataframe iterrows with tqdm for progress tracking\n",
    "        for idx, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Indexing\"):\n",
    "            document = {\n",
    "                \"embedding\": embeddings[idx].tolist(),\n",
    "                \"city\": row['City'],\n",
    "                \"Job title\": row['Job Title'],\n",
    "                \"Job Description\": row[\"Job Description\"]\n",
    "            }\n",
    "            self.es.index(index=self.index_name, body=document)\n",
    "\n",
    "# Create an instance of JobPostingDB and set up the index, and ingest the data from Job posting dataframe\n",
    "db = JobPostingDB()\n",
    "db.setup_index()\n",
    "db.index_dataframe(job_posting_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NlpEngine:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the NLP Engine with the necessary models.\"\"\"\n",
    "        self.embedding_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "        self.ner_model = NamedEntityRecognizer()  # Assuming you've already defined the NER class from above\n",
    "\n",
    "    def generate_embedding(self, text: str) -> list:\n",
    "        \"\"\"\n",
    "        Generate embeddings for the given text.\n",
    "\n",
    "        :param text: The input text.\n",
    "        :return: List containing embeddings.\n",
    "        \"\"\"\n",
    "        return self.embedding_model.encode(text)\n",
    "\n",
    "    def extract_location(self, text: str) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Extract the location entity from the text.\n",
    "\n",
    "        :param text: The input text.\n",
    "        :return: Extracted location entity or None.\n",
    "        \"\"\"\n",
    "        entities = self.ner_model.extract_entities(text)\n",
    "        # return entities.get('LOCATION')\n",
    "        return 'USA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "class SearchEngine:\n",
    "    def __init__(self, host: str=\"http://localhost:9200/\", user: str=\"USERNAME\", password: str=\"PASSWORD\"):\n",
    "        \"\"\"\n",
    "        Initialize the search engine with connections to Elasticsearch and NLP tools.\n",
    "\n",
    "        :param host: Elasticsearch host URL.\n",
    "        :param user: Elasticsearch username.\n",
    "        :param password: Elasticsearch password.\n",
    "        \"\"\"\n",
    "        # self.es = Elasticsearch([host], basic_auth=(user, password))\n",
    "        self.es = Elasticsearch([{'host': 'localhost', 'port': 9200, 'scheme': 'http'}])\n",
    "        self.nlp = NlpEngine()\n",
    "        print(\"conn est\")\n",
    "    def semantic_search(self, query: str, index_name: str=\"job_postings\") -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Perform a search based on the user's query using k-NN.\n",
    "    \n",
    "        :param query: The user's search query.\n",
    "        :param index_name: The name of the index in Elasticsearch to search on.\n",
    "        :return: List of best-matching documents.\n",
    "        \"\"\"\n",
    "        print(\"semantic-------- est\")\n",
    "\n",
    "        # Extract location and generate embedding from the query\n",
    "        location = self.nlp.extract_location(query)\n",
    "        embedding = self.nlp.generate_embedding(query)\n",
    "\n",
    "        print(\"c------------------est\")\n",
    "        \n",
    "        # Create a k-NN component\n",
    "        knn_component = {\n",
    "            \"field\": \"embedding\",\n",
    "            \"query_vector\": embedding.tolist(),\n",
    "            \"k\": 10,\n",
    "            \"num_candidates\": 10,  \n",
    "            \"boost\": 0.8\n",
    "        }\n",
    "    \n",
    "        # Structure the primary query\n",
    "        main_query = {\n",
    "            \"bool\": {\n",
    "                \"must\": [{\"match_all\": {}}]\n",
    "            }\n",
    "        }\n",
    "    \n",
    "        # If a location is extracted from the query, modify the primary query\n",
    "        if location:\n",
    "            main_query[\"bool\"][\"should\"] = [\n",
    "                {\"term\": {\"city\": location}},\n",
    "                {\"match\": {\"city\": {\"query\": location, \"boost\": 0.2}}}\n",
    "            ]\n",
    "    \n",
    "        # Combine the main query and the k-NN component\n",
    "        final_search_body = {\n",
    "            \"query\": main_query,\n",
    "            \"knn\": knn_component,\n",
    "            \"source\": [\"city\", \"Job title\"],\n",
    "            \"size\": 10\n",
    "        }\n",
    "\n",
    "        # Execute the search\n",
    "        res = self.es.search(index=index_name, body=final_search_body)\n",
    "        return [hit[\"_source\"] for hit in res[\"hits\"][\"hits\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'match_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43mmatch_score\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.1\u001b[39m \u001b[38;5;241m*\u001b[39m knn_score\n",
      "\u001b[0;31mNameError\u001b[0m: name 'match_score' is not defined"
     ]
    }
   ],
   "source": [
    "score = 0.9 * match_score + 0.1 * knn_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4886/1377762900.py:60: DeprecationWarning: Using 'source' alias in 'body' is deprecated and will be removed in a future version of elasticsearch-py. Use '_source' directly instead. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  res = self.es.search(index=index_name, body=final_search_body)\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "BadRequestError(400, 'parsing_exception', 'Unknown key for a START_OBJECT in [knn].')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m search_engine \u001b[38;5;241m=\u001b[39m SearchEngine()\n\u001b[0;32m----> 2\u001b[0m \u001b[43msearch_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msemantic_search\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mJob in Web Programming\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[36], line 60\u001b[0m, in \u001b[0;36mSearchEngine.semantic_search\u001b[0;34m(self, query, index_name)\u001b[0m\n\u001b[1;32m     52\u001b[0m final_search_body \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: main_query,\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mknn\u001b[39m\u001b[38;5;124m\"\u001b[39m: knn_component,\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcity\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob title\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     57\u001b[0m }\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Execute the search\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal_search_body\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [hit[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_source\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m hit \u001b[38;5;129;01min\u001b[39;00m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhits\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhits\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/elasticsearch/_sync/client/utils.py:446\u001b[0m, in \u001b[0;36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    444\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/elasticsearch/_sync/client/__init__.py:3836\u001b[0m, in \u001b[0;36mElasticsearch.search\u001b[0;34m(self, index, aggregations, aggs, allow_no_indices, allow_partial_search_results, analyze_wildcard, analyzer, batched_reduce_size, ccs_minimize_roundtrips, collapse, default_operator, df, docvalue_fields, error_trace, expand_wildcards, explain, ext, fields, filter_path, from_, highlight, human, ignore_throttled, ignore_unavailable, indices_boost, knn, lenient, max_concurrent_shard_requests, min_compatible_shard_node, min_score, pit, post_filter, pre_filter_shard_size, preference, pretty, profile, q, query, rank, request_cache, rescore, rest_total_hits_as_int, routing, runtime_mappings, script_fields, scroll, search_after, search_type, seq_no_primary_term, size, slice, sort, source, source_excludes, source_includes, stats, stored_fields, suggest, suggest_field, suggest_mode, suggest_size, suggest_text, terminate_after, timeout, track_scores, track_total_hits, typed_keys, version, body)\u001b[0m\n\u001b[1;32m   3834\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m __body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3835\u001b[0m     __headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 3836\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m   3837\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m__path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__body\u001b[49m\n\u001b[1;32m   3838\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/elasticsearch/_sync/client/_base.py:320\u001b[0m, in \u001b[0;36mBaseClient.perform_request\u001b[0;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 320\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTP_EXCEPTIONS\u001b[38;5;241m.\u001b[39mget(meta\u001b[38;5;241m.\u001b[39mstatus, ApiError)(\n\u001b[1;32m    321\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage, meta\u001b[38;5;241m=\u001b[39mmeta, body\u001b[38;5;241m=\u001b[39mresp_body\n\u001b[1;32m    322\u001b[0m     )\n\u001b[1;32m    324\u001b[0m \u001b[38;5;66;03m# 'X-Elastic-Product: Elasticsearch' should be on every 2XX response.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verified_elasticsearch:\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;66;03m# If the header is set we mark the server as verified.\u001b[39;00m\n",
      "\u001b[0;31mBadRequestError\u001b[0m: BadRequestError(400, 'parsing_exception', 'Unknown key for a START_OBJECT in [knn].')"
     ]
    }
   ],
   "source": [
    "search_engine = SearchEngine()\n",
    "search_engine.semantic_search(\"Job in Web Programming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
